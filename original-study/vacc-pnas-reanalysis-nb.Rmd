---
title: "PNAS re-analysis notebook"
author: "Derek Powell"
output: 
  html_notebook: 
    code_folding: hide
---

This is a notebook to re-analyze the data from the PNAS paper "Countering Antivaccination Attitudes" using more appropriate statistical methods, such as ordinal HLM and beta regression. These analyses are being conducted in anticipation of a follow-up replication study.

# Beta Regression

Beta regression is a more appropriate approach to analyzing bounded, skewed, and heteroscedastic data. Which is exactly what our vaccine attitude scale measures are. 

For more info, see [this paper](https://www.ncbi.nlm.nih.gov/pubmed/16594767), cited below.

> Smithson M, Verkuilen J: A better lemon squeezer? Maximum-likelihood regression with beta-distributed dependent variables. Psychol Methods. 2006, 11 (1): 54-71.)

Also good to read the [betareg vignette](https://cran.r-project.org/web/packages/betareg/vignettes/betareg.pdf) (or run `vignette("betareg")`).

```{r, echo=FALSE}
library(tidyverse)
library(brms)

vaccAll <- read.csv("vacc-hphh-pubdata.csv") %>% 
  as_tibble() %>% 
  mutate(Participant = seq(1:n())) %>%
  filter(EligibleToReturn==1)

vaccW <- vaccAll %>%
  mutate(pretest = PreTestVaccinationAttitude, posttest = PostTest.Vaccination.Attitude) %>%
  filter(Returned == 1, Excluded == 0) %>%
  mutate(Condition = relevel(Condition, ref="Control")) %>%
  rename(condition = Condition)

```

# Original Analysis (change scores)

```{r}
fit.change <- lm(change ~ condition, data = vaccW %>% mutate(change = posttest - pretest))
summary(fit.change)
```

## OLS analysis

```{r}
fit.ols <- lm(scale(posttest) ~ scale(pretest) * condition, data = vaccW)

# fit.ols <- lm(scale(posttest) ~ scale(pretest) + condition, contrasts = list(condition = contr.sum), data = vaccW)

summary(fit.ols)
```

## Beta Regression

Now we can run a beta regression using the `betareg` package. This uses maximum-likelihood estimation and provides frequentist p-values, etc. Before conducting beta regression, the response variable must be rescaled on to the bounded (exclusive) interval $(0, 1)$.

```{r}
library(betareg)
set.seed(123)

rescale_beta <- function(x, lower, upper) {
  # rescales onto the open interval (0,1)
  # rescales over theoretical bounds of measurement, specified by "upper" and "lower"
  # based on Smithson & Verkuilen (2006), though this is not as principled as you might think
  # see http://dx.doi.org/10.1037/1082-989X.11.1.54.supp

  N <- length(x)
  res <- (x - lower) / (upper - lower)
  res <- (res * (N - 1) + .5) / N

  return(as.vector(res))
}

fit.beta <- betareg(
  posttest ~ scale(pretest) + condition,
  data = vaccW %>% mutate(posttest = rescale_beta(posttest, 1, 6))
)

summary(fit.beta)
```

Comparing models ...

```{r}
fit.olsScaled <- lm(
  posttest ~ scale(pretest) * condition,
  data = vaccW %>% mutate(posttest = rescale_beta(posttest, 1, 6))
)

AIC(fit.olsScaled)
AIC(fit.beta)

```

The beta regression model is **MUCH** preferred by AIC. Its results are also more sensible, capturing the main effect of Disease Risk intervention without the spurious interaction induced by the scale bounds and/or regression to the mean. (Comparing models within the beta family, a non-interactive model is slightly preferred, which is what I showed above).


```{r}

vaccW %>%
  select(condition, pretest, posttest) %>%
  mutate(posttest = rescale_beta(posttest, 1, 6)) %>%
  bind_cols(predict(fit.beta) %>% as_tibble()) %>%
  rename(predictionBeta = value) %>%
  bind_cols(predict(fit.olsScaled) %>% as_tibble()) %>%
  rename(predictionOLS = value) %>%
  
  ggplot(aes(x = pretest, y = posttest, color = condition)) +
  geom_jitter(height = .1, width = .05, alpha = .8, shape = 1) +
  geom_line(aes(y = predictionBeta, linetype = "Beta")) +
  geom_line(aes(y = predictionOLS, linetype = "OLS")) +
  # geom_line(aes(y = predict(fit.ols, vaccW),
  #               colour = "OLS", linetype = "OLS")) +
  # scale_colour_manual("", values = c("red", "blue")) +
  scale_linetype_manual("", values = c("solid", "dashed")) +
  theme_bw()
```

## with BRMS

Now for fun, we can do this in BRMS for both models. Short answer is everything looks exactly the same.

```{r}
library(brms)
fit_brm_gauss <- brm(
  posttest ~ pretest + condition,
  data = vaccW,
  family = gaussian(), # student(), #cumulative(), #bernoulli(), etc
  control = list(adapt_delta = .80),
  cores = parallel::detectCores(),
  iter = 2000
)

summary(fit_brm_gauss)
```


```{r}
fit_brm_beta <- brm(
  posttest ~ pretest + condition,
  data = vaccW %>% mutate(posttest = rescale_beta(posttest, 1, 6)),
  family = Beta(), # student(), #cumulative(), #bernoulli(), etc
  control = list(adapt_delta = .85),
  cores = parallel::detectCores(),
  iter = 2000
)

summary(fit_brm_beta)
```

And we can compare the models using loo (analogous to AIC). Again, beta does far better.

```{r}
loo(fit_brm_gauss)
loo(fit_brm_beta)
```

And finally we can create marginal effects plots from both models. Ignoring the scale differences, they look pretty similar.

```{r}
me1 <- marginal_effects(fit_brm_beta, effects = "Condition", probs = c(.25, .75))
plt.me1 <- plot(me1,
  effects = "Condition",
  plot = FALSE,
  rug = TRUE,
  theme = ggplot2::theme_get()
)[[1]] + labs(title = "Beta") + theme_bw()

me2 <- marginal_effects(fit_brm_gauss, effects = "Condition", probs = c(.25, .75))
plt.me2 <- plot(me2,
  effects = "Condition",
  plot = FALSE,
  rug = TRUE,
  theme = ggplot2::theme_get()
)[[1]] + labs(title = "Gaussian") + theme_bw()

library(gridExtra)
grid.arrange(plt.me1, plt.me2, ncol = 2)
```


# Predicting "response"

beta regression

```{r}
library(brms)
# untested: 3/19/18, 8:10 PM
fit_brm_beta_resp <- brm(
  response ~ phase * condition + (1|Participant),
  data = vaccW %>%
    mutate(
      posttest = rescale_beta(posttest, 1, 6),
      pretest = rescale_beta(pretest, 1, 6)
    ) %>%
    gather(phase, response, pretest, posttest),
  family = Beta(), # student(), #cumulative(), #bernoulli(), etc
  control = list(adapt_delta = .85),
  cores = parallel::detectCores(),
  iter = 2000
)

summary(fit_brm_beta_resp)
```

```{r}
vacc <- vaccW %>%
  rename(
    Healthy_post = Healthy_VaxscalePosttest,
    Diseases_post = Diseases_VaxScalePosttest_Reversed,
    Doctors_post = Doctors_VaxScalePostTest,
    SideEffects_post = Sideeffects_VaxScalePostTest_Reversed,
    PlanTo_post = Planto_VaxScalePostTest,
    Healthy_pre = Healthy_VaxscalePretest,
    Diseases_pre = Diseases_VaxScalePretest_Reversed,
    Doctors_pre = Doctors_VaxScalePreTest,
    SideEffects_pre = Sideeffects_VaccScalePreTest_Reversed,
    PlanTo_pre = Planto_VaxScalePreTest
  ) %>%
  # select(condition,ends_with("_pre"),ends_with("_post")) %>%
  gather(
    item,
    agree,
    ends_with("_pre"), 
    ends_with("_post")
  ) %>%
  mutate(phase = ifelse(grepl("_pre", item), "pretest", "posttest")) %>%
  mutate(item = sub("_pre", "", item)) %>%
  mutate(item = sub("_post", "", item))
  
```

predicing "response" from phase and condition, ordinal HLM

```{r}
# untested: 3/19/18, 8:10 PM
fit_brm_cum_resp <- brm(
  agree ~ phase * condition + (1|Participant) + (1|item),
  data = vacc,
  family = cumulative(), # student(), #cumulative(), #bernoulli(), etc
  control = list(adapt_delta = .85),
  cores = parallel::detectCores(),
  iter = 2000
)

summary(fit_brm_cum_resp)
```

predicting posttest from pretest, ordinal HLM

```{r}
# untested: 3/19/18, 8:10 PM
fit_brm_cum_posttest <- brm(
  posttest ~ pretest + condition + (1 | Participant) + (1 | item),
  data = vacc %>%
    filter(phase == "posttest") %>%
    rename(posttest = agree),
  family = cumulative(), # student(), #cumulative(), #bernoulli(), etc
  control = list(adapt_delta = .85),
  cores = parallel::detectCores(),
  iter = 2000
)

summary(fit_brm_cum_resp)
```

# SessionInfo

```{r}
sessionInfo()
```

