---
title: "Countering AntiVaccination Attitudes Replication"
author: "Derek Powell & Kara Weisman"
output: 
  html_notebook: 
    code_folding: hide
---

__NOTE: These are preliminary analyses as of 3/26/18, 4:08 PM__

This is an R notebook to analyze the data from the Countering AntiVaccination Attitudes (CAVA) replication study.

This replication roject was preregistered: https://osf.io/j5n4e/

- Part 1 of the study was conducted on March 21, 2018
- Part 2 of the study was conducted on March 22, 2018 (with a few Ps collected March 23, 2018)

```{r}
# load packages
library(tidyverse)
library(brms)

if (!require(betareg)) {
  install.packages("betareg")
}
library(betareg)

if (!require(effsize)) {
  install.packages("effsize")
}
library(effsize)

# Define some functions ...
read_qualtrics_csv <- function(fname) {
  df <- read.csv(fname, skip = 3, header = F)
  headers <- as.matrix(read.csv(fname, skip = 0, header = F, nrows = 1, as.is = T))
  colnames(df) <- headers
  df <- df[which(df[, "DistributionChannel", ] == "anonymous"), ] # remove survey previews
  total_n <- nrow(df)

  # remove unused qualtrics variables
  remove_cols <- c(
    "RecipientLastdata",
    "RecipientFirstdata",
    "RecipientEmail",
    "Finished",
    "ResponseId",
    "ExternalReference",
    "DistributionChannel",
    "UserLanguage",
    "Status"
  )

  df <- df[, -which(colnames(df) %in% remove_cols)]

  return(df)
}

rescale_beta <- function(x, lower, upper) {
  # rescales onto the open interval (0,1)
  # rescales over theoretical bounds of measurement, specified by "upper" and "lower"
  # based on Smithson & Verkuilen (2006), though this is not as principled as you might think
  # see http://dx.doi.org/10.1037/1082-989X.11.1.54.supp

  N <- length(x)
  res <- (x - lower) / (upper - lower)
  res <- (res * (N - 1) + .5) / N

  return(as.vector(res))
}
```

```{r}
# working from raw qualtrics with workerIds anonymized

# Data preprocessing ...
d_pre <- read_qualtrics_csv("data/Vaccine+PNAS+replication+day1-2018-03-23.csv") %>%
  select(workerId, age:Vax1_Vax1_36, eligible, study_time, payment)

d_post <- read_qualtrics_csv("data/Vaccine+PNAS+replication+day2-2018-03-23.csv") %>%
  select(workerId, condition, vax2_Vax1_1:vax2_Vax1_36, parent:SC1)

d_merge <- merge(d_pre,d_post, by="workerId") %>%
  as_tibble() %>%
  filter(SC1==4) %>%
  filter(Attention==1)

# rename variables and do reverse coding

d_untidy <- d_merge %>%
  select(-Vax1_Vax1_check,-vax2_Vax1_check) %>%
  rename(
    vax_pre_risks = Vax1_Vax1_1,
    vax_pre_herd = Vax1_Vax1_2,
    vax_pre_plan = Vax1_Vax1_3,
    vax_pre_uncommon = Vax1_Vax1_4,
    vax_pre_doctors = Vax1_Vax1_5,
    vax_pre_autism = Vax1_Vax1_6,
    vaxIntent_pre_Iwould = Vax1_Vax1_33,
    vaxIntent_pre_spreadOut = Vax1_Vax1_34,
    vaxIntent_pre_confident = Vax1_Vax1_35,
    vaxIntent_pre_wouldNever = Vax1_Vax1_36,
    vax_post_risks = vax2_Vax1_1,
    vax_post_herd = vax2_Vax1_2,
    vax_post_plan = vax2_Vax1_3,
    vax_post_uncommon = vax2_Vax1_4,
    vax_post_doctors = vax2_Vax1_5,
    vax_post_autism = vax2_Vax1_6,
    vaxIntent_post_Iwould = vax2_Vax1_33,
    vaxIntent_post_spreadOut = vax2_Vax1_34,
    vaxIntent_post_confident = vax2_Vax1_35,
    vaxIntent_post_wouldNever = vax2_Vax1_36
  ) %>%
  mutate( # implement reverse coding
    vax_pre_risks = 7 - vax_pre_risks,
    vax_post_risks = 7 - vax_post_risks,
    vax_pre_uncommon = 7 - vax_pre_uncommon,
    vax_post_uncommon = 7 - vax_post_uncommon,
    vaxIntent_pre_spreadOut = 7 - vaxIntent_pre_spreadOut,
    vaxIntent_post_spreadOut = 7 - vaxIntent_post_spreadOut,
    vaxIntent_pre_wouldNever = 7 - vaxIntent_pre_wouldNever,
    vaxIntent_post_wouldNever = 7 - vaxIntent_post_wouldNever
  ) %>% 
  mutate( # add duplicates to cover both scales
    vaxIntent_pre_risks = vax_pre_risks,
    vaxIntent_post_risks = vax_post_risks
  ) 

# more munging to tidy data ...
d <- d_untidy %>%
  gather(item, rating, contains("vax")) %>%
  mutate(
    rating = as.integer(rating),
    phase = ifelse(grepl("_pre_",item),"pretest","posttest"),
    Scale = ifelse(grepl("vaxIntent_",item), "vaxIntent", "vaxAttitude"),
    condition = factor(condition, 
                       levels=c("bird","autism","cdc_danger"),
                       labels=c("Control","Autism Correction", "Disease Risk"))
    ) %>%
  mutate(condition = relevel(condition, ref="Control")) %>%
  mutate(Scale = ifelse(grepl("autism",item), "autism", Scale)) %>%
  mutate(item=gsub("vax_pre_","", item)) %>%
  mutate(item=gsub("vax_post_","", item)) %>%
  mutate(item=gsub("vaxIntent_pre_","", item)) %>%
  mutate(item=gsub("vaxIntent_post_","", item))

# and reducing to a "summary" dataset
d_sum <- d %>%
  filter(Scale=="vaxAttitude") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating) %>%
  mutate(change = posttest - pretest)
```


# Preliminaries

## Check scale reliability and confirm proper reverse coding

For vaccine attitudes ...

```{r}
d %>% filter(Scale=="vaxAttitude", phase=="pretest") %>% spread(item, rating) %>% select(doctors:uncommon) %>% psych::alpha()

d %>% filter(Scale=="vaxAttitude", phase=="posttest") %>% spread(item, rating) %>% select(doctors:uncommon) %>% psych::alpha()
```

for vaccine intentions ...

```{r}
d %>% filter(Scale=="vaxIntent", phase=="pretest") %>% spread(item, rating) %>% select(confident:wouldNever) %>% psych::alpha()

d %>% filter(Scale=="vaxIntent", phase=="posttest") %>% spread(item, rating) %>% select(confident:wouldNever) %>% psych::alpha()
```

Scales have been properly coded and can be considered reliable. 

## Testing for pretest differences

Before considering change scores, we should confirm there are no meaningful pretest differences between conditions. The plot below suggests 

```{r, fig.align="center"}
# d_sum %>%
#   ggplot(aes(x=pretest, fill=condition)) +
#   geom_density(alpha=.25) +
#   theme_minimal()

d_sum %>%
  ggplot(aes(x = condition, fill = condition, colour = condition, y = pretest)) +
  geom_violin(width = .5, alpha = .25) +
  stat_summary(fun.data = "mean_cl_boot", fun.args = (list(B = 10000, conf.int = .95)), color = "grey20", shape = 16) +
  theme_minimal() +
  labs(title = "Pretest Scores", y = "Pretest Scores", x = "Condition") +
  annotate("text", label = "Error bars represent 95% bootstrap CI of the mean", x = 2, y = .5)
```

```{r}
fit_pre <- betareg(rescale_beta(pretest,1,6) ~ condition, data=d_sum)
summary(fit_pre)
```

Participants in the autism correction and disease risk conditions had slightly (tho non-significantly) higher pretest scores than participants in the control condition. Presumably, this should have made it all the more difficult to improve attitudes in those conditions relative to control.

# I. Direct Replication

## Plotting Change Scores

Plotting to replicate Figure 1 from _PNAS_ paper.

```{r}
# standard error function
stderr <- function(x) {
          sqrt(var(x[!is.na(x)]) / length(x[!is.na(x)]))
}

d %>%
  filter(Scale=="vaxAttitude") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating) %>%
  summarize(change_score = posttest-pretest) %>%
  group_by(condition) %>%
  summarize(mean_change = mean(change_score),
            ul = mean(change_score) + stderr(change_score),
            ll = mean(change_score) - stderr(change_score)) %>%
  ggplot(aes(x=condition, fill=condition, y = mean_change, ymin=ll, ymax=ul)) +
  geom_bar(stat="identity") +
  geom_errorbar(width=.25) +
  theme_minimal() +
  labs(title="Change Score Analysis",
       subtitle = "Error bars are standard errors",
       y = "Mean Change Score",
       x = "Condition",
       fill = "Condition")
```

Anaysis of change scores shows significant improvement in disease risk condition. This analysis replicates the original analyses and the primary pre-registered analysis. __We directly replicate the original findings.__

```{r}
fit_aov <- aov(change ~ condition, data = d_sum)
summary(fit_aov)

t.test(change ~ condition, data = d_sum %>% filter(condition!="Autism Correction"))
dr_control_D <- suppressWarnings(cohen.d(change ~ condition, data = d_sum %>% filter(condition!="Autism Correction"))$estimate)

t.test(change ~ condition, data = d_sum %>% filter(condition!="Control"))
dr_autism_D <- suppressWarnings(cohen.d(change ~ condition, data = d_sum %>% filter(condition!="Control"))$estimate)
```

Comparing the magnitude of the effects, the effect sizes in this replication study are smaller than what was originally observed, with the Disease Risk vs Control D = `r as.numeric(dr_control_D) %>% round(3)` (compared with .41 originally) and Disease Risk vs Autism Correction D = `r as.numeric(dr_autism_D) %>% round(3)` (compared with .33 originally).

# II. "Best Model" Replication

ANOVA on change scores is not the optimal approach to analyzing these data. Next, we explore some better ways of modeling the data from this experiment, and evaluate whether these improved statistical models also support the conclusions drawn in the original paper.

The change score analysis has a few issues:

1. Fails to control for or reveal pretest differences between conditions
2. Change scores influenced by both pre-test and posttest measurement error (likely contaminated by regression to the mean)
3. Fails to respect boundaries of original scale (e.g., for Ps near ceiling, negative change scores are largely uninformative)
4. Assumes normal distribution (change scores somewhat non-normal)

Other approaches can avoid some or all of these issues. 

## Posttest scores by condition, controlling for pretest

### Linear regression model

Using a linear regression predicting posttest from condition and pretest begins to mitigate the first two issues: it helps to control for pretest differences among conditions (though these can still complicate inference) and allows for modeling error in predicting posttest scores from pretest scores.

```{r}
fit_lm <- lm(posttest ~ scale(pretest) + condition,
           data=d_sum)

summary(fit_lm)
```

However, this analyses fails to account for the boundedness of the scale nor the non-normal distribution of responses.

### Beta Regression

Beta regression is a more appropriate approach to analyzing bounded, skewed, and heteroscedastic data--three properties of the vaccine attitudes scale responses. For more info, see [this paper](https://www.ncbi.nlm.nih.gov/pubmed/16594767): Smithson M, Verkuilen J (2006) A better lemon squeezer? Maximum-likelihood regression with beta-distributed dependent variables. _Psychol Methods._ 11 (1): 54-71.

The use of Beta regression addresses all four of the major concerns in the change score analyses.

```{r}
fit_beta <- betareg(rescale_beta(posttest,1,6) ~ scale(pretest) * condition,
           data=d_sum)

summary(fit_beta)
```

```{r, include=F}
fit_lm_scaled <- lm(rescale_beta(posttest,1,6) ~ scale(pretest) + condition,
           data=d_sum)
```

Beta regression is justified over linear regression on theoretical grounds, but it is also supported on empirical grounds. Comparing models by AIC, the beta regression model is very strongly preferred, with _AIC_ = `r round(AIC(fit_beta),1)` versus `r round(AIC(fit_lm_scaled),1)` for the linear regression model.

### Bayesian beta regression

We also conduct beta regression using bayesian estimation in BRMS.

```{r}
# fit_brm_beta <- brm(
#   rescale_beta(posttest, 1, 6) ~ scale(pretest) + condition,
#   data = d_sum,
#   family = Beta(), # student(), #cumulative(), #bernoulli(), etc
#   control = list(adapt_delta = .85),
#   cores = parallel::detectCores(),
#   iter = 2000
# )
```

This allows us to plot condition effects estimated from the model while marignalizing over pretest scores, along with 50% credible intervals.

```{r}
# summary(fit_brm_beta)
# 
# me2 <- marginal_effects(fit_brm_beta, effects = "condition", probs = c(.25, .75))
# plt.me2 <- plot(me2,
#   effects = "condition",
#   plot = FALSE,
#   rug = TRUE,
#   theme = ggplot2::theme_get()
# )[[1]] + 
#   labs(title = "Beta Regression: Marginal Effects") + 
#   theme_minimal()
# 
# plt.me2
```

### Hierarchical ordinal regression

A final concern in all of the above analyses, on change scores or on posttest scores, is the use of "scores". That is, the averaging of several ordinal likert scale ratings into a continuous scale variable. Using hierarchical ordinal regression, we can avoid this averaging, and directly model the observed data. This accounts for the ordinal nature of the underlying response variable, as well as possible differences among scale items that are lost to averaging.

```{r}
# fit_brm_cum_posttest <- brm(
#   posttest ~ pretest + condition + (1 | workerId) + (1 | item),
#   data = d %>% filter(Scale=="vaxAttitude") %>% spread(phase, rating),
#   family = cumulative(), # student(), #cumulative(), #bernoulli(), etc
#   control = list(adapt_delta = .85),
#   cores = parallel::detectCores(),
#   iter = 2000
# )
```

```{r}
# summary(fit_brm_cum_posttest)
```

## Further analyses

To be explored:

- Examine demographics of participants
- Examine predictions of vaccine behavior for both scales (started)
- Estimate predicted reduction in vaccine refusals based on attitude change and behavior

#### Vaccine behavior: delay and refusal 

How many parents have delayed, refused, or sought exemptions from vaccines? _I just observed that the exemption item was not coded correctly on Qualtrics, have corrected it there but will need to redownload data - 3/26/18, 3:48 PM._


```{r}
d %>%
  group_by(parent, workerId) %>%
  summarize(
    flu = mean(flu, na.rm=TRUE),
    flu_next = mean(flu2, na.rm=TRUE),
    flu_child = mean(flu3, na.rm=TRUE),
    flu_child_next = mean(flu4, na.rm=TRUE),
    delay = mean(delay, na.rm=TRUE),
    refuse = mean(refuse, na.rm=TRUE)) %>%
  summarize(
    flu = mean(flu, na.rm=TRUE),
    flu_next = mean(flu_next, na.rm=TRUE),
    flu_child = mean(flu_child, na.rm=TRUE),
    flu_child_next = mean(flu_child_next, na.rm=TRUE),
    delay = mean(delay, na.rm=TRUE),
    refuse = mean(refuse, na.rm=TRUE))
```

How do pretest vaccine attitudes predict refusals?

```{r}
d_sum_behavior <- d %>%
  filter(Scale=="vaxAttitude") %>%
  mutate(young_parent = ifelse( ((parent == 1 & youngest < 12) | (parent == 0 & hope_par == 1)), 1, 0 )) %>%
  mutate(young_parent = ifelse(is.na(young_parent),0,young_parent)) %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating),
            young_parent = first(young_parent),
            refuse = first(refuse),
            delay = first(delay),
            flu = first(flu),
            flu_child = first(flu3)) %>%
  spread(phase, mean_rating) %>%
  mutate(change = posttest - pretest)

fit_refuse <- glm(refuse ~ pretest, data = d_sum_behavior, family="binomial")
summary(fit_refuse)
```

```{r}

# here's some sloppy code to plot that model

model <- glm(refuse ~ pretest,
  data = d_sum_behavior,
  family=binomial) #etc

temp.data <- data.frame(
  pretest =  seq(from=1, to = 6, length.out = 300))

temp.data <- cbind(temp.data, predict(model, temp.data, type = "link", se.fit=TRUE))

temp.data <- within(temp.data, {
  yHat <- model$family$linkinv(fit)
  LL <- model$family$linkinv(fit - 1.96 * se.fit)
  UL <- model$family$linkinv(fit + 1.96 * se.fit)
})

plt.refuse <- ggplot(temp.data, aes(x = pretest, y = yHat)) +
  geom_ribbon(aes(ymin = LL, ymax = UL), fill="grey", alpha = .4) +
  geom_line(colour = "blue") +
  labs(x = "Vaccine attitudes (pre-test)", y = "P(Refusal)", title="Child Vaccination refusals") +
  geom_jitter(data=d_sum_behavior, 
              aes(x=pretest, y=refuse), 
              inherit.aes = FALSE,
              height=.025,
              width=.05,
              alpha=.5,
              shape=1) +
  theme_minimal(base_size = 18) +
  theme(aspect.ratio = 1)

plt.refuse

```

#### Parents vs non-parents

How many Ps are parents?

```{r}
d %>% 
  group_by(condition, workerId) %>%
  summarize(parent = first(parent)) %>%
  summarize(prop_parent = mean(parent))
  
```

Looks like approximately 44-45% of participants are parents. Let's see how the age of their youngest children breaks down.

```{r}

d <- d %>% 
  mutate(youngest = as.numeric(as.character(youngest)),
         oldest = as.numeric(as.character(oldest)),
         youngest = ifelse(num_child==1,oldest,youngest))
d %>%
  group_by(workerId) %>%
  summarize(youngest = mean(youngest)) %>%
  ggplot(aes(x=youngest)) +
  geom_histogram()
```

And how many are planning to become parents soon?

- 0 = no
- 1 = Yes, in next 1-2 years
- 2 = Yes, in next 2-5 years
- 3 = yes, but not for 5 or more years

```{r}
d %>%
  group_by(workerId) %>%
  summarize(hope_par = first(hope_par)) %>%
  ggplot(aes(x=hope_par)) +
  geom_histogram()
```

Here we can focus in on the primary demographic of our interventions, parents of young children and those who are soon to be parents. Below, we code as `young_parent` parents with children under 12 and people who hope to become parents within the next 2 years.

```{r}

d_sum_pars <- d %>%
  filter(Scale=="vaxAttitude") %>%
  mutate(young_parent = ifelse( ((parent == 1 & youngest < 12) | (parent == 0 & hope_par == 1)), 1, 0 )) %>%
  mutate(young_parent = ifelse(is.na(young_parent),0,young_parent)) %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating),
            young_parent = first(young_parent)) %>%
  spread(phase, mean_rating) %>%
  mutate(change = posttest - pretest)

fit_beta_pars <- betareg(rescale_beta(posttest,1,6) ~ scale(pretest) + condition*young_parent,
           data=d_sum_pars)

summary(fit_beta_pars)
```



#### Effect of autism correction condition on "autism" item

All told, the Autism Correction condition did not affect overall vaccine attitudes. However, it did clearly reduce agreement with the added item "Some vaccines cause autism in healthy children" (as found originally). So, it's possible that people accept the information in the condiiton, but that it is only a very small part of what drives their overall attitudes toward vaccination.

```{r}
d %>%
  filter(Scale=="autism") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating) %>%
  summarize(change_score = posttest-pretest) %>%
  group_by(condition) %>%
  summarize(mean_change = mean(change_score),
            ul = mean(change_score) + stderr(change_score),
            ll = mean(change_score) - stderr(change_score)) %>%
  ggplot(aes(x=condition, fill=condition, y = mean_change, ymin=ll, ymax=ul)) +
  geom_bar(stat="identity") +
  geom_errorbar(width=.25) +
  theme_minimal() +
  labs(title="Change Score Analysis: 'Autism' Item",
       y = "Mean Change Score",
       x = "Condition",
       fill = "Condition")
```

# III. "Vaccine intent" scale results

Here's a plot of the change scores for the vaccine intent scale across conditions. The differences here are somewhat smaller than for "vaccine attitudes", but they appear significant.

```{r}
d %>%
  filter(Scale=="vaxIntent") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating) %>%
  summarize(change_score = posttest-pretest) %>%
  group_by(condition) %>%
  summarize(mean_change = mean(change_score),
            ul = mean(change_score) + stderr(change_score),
            ll = mean(change_score) - stderr(change_score)) %>%
  ggplot(aes(x=condition, fill=condition, y = mean_change, ymin=ll, ymax=ul)) +
  geom_bar(stat="identity") +
  geom_errorbar(width=.25) +
  theme_minimal() +
  labs(title="Change Score Analysis: Vaccine Intent",
       subtitle = "Error bars are standard errors")
```

```{r}
d %>%
  filter(Scale=="vaxIntent") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating) %>%
  summarize(change_score = posttest-pretest) %>%
  ggplot(aes(x = change_score, fill = condition)) +
  # geom_histogram(binwidth = 0.25, alpha = 0.25, position = "identity") +
  geom_density(alpha = 0.25, position = "identity") +
  geom_vline(xintercept = 0, lty = 2) +
  theme_minimal() +
  labs(title = "Distribution of Change Scores: Vaccine Intent",
       x = "Change Score", y = "Density", fill = "Condition")

d %>%
  filter(Scale=="vaxIntent") %>%
  mutate(phase = factor(phase, levels = c("pretest", "posttest"))) %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  ggplot(aes(x = phase, color = condition, y = mean_rating)) +
  facet_grid(~ condition) +
  geom_line(aes(group = workerId), alpha = 0.1, size = 1) +
  geom_point(alpha = 0.1, size = 1) +
  scale_y_continuous(limits = c(0, 6), breaks = 0:6) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Changes at the Individual Level: Vaccine Intent",
       x = "Timepoint", y = "Vaccine Intent Score")
```

## Linear regression

Under the linear regression model, the contrast between control and disease risk conditions is just barely non-significant at the $\alpha = .05$ level.

```{r}
d_sum_intent <- d %>%
  filter(Scale == "vaxIntent") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating)

fit_lm_intent <- lm(posttest ~ scale(pretest) + condition, data = d_sum_intent)
summary(fit_lm_intent)
```

## Beta regression

However, by beta regression, the main contrast is significant.

```{r}
d_sum_intent <- d %>%
  filter(Scale == "vaxIntent") %>%
  group_by(workerId, condition, phase) %>%
  summarize(mean_rating = mean(rating)) %>%
  spread(phase, mean_rating)

fit_beta_intent <- betareg(
  rescale_beta(posttest, 1, 6) ~ scale(pretest) * condition,
  data = d_sum_intent
)

summary(fit_beta_intent)
```

```{r include = F}
fit_lm_intent_scaled <- lm(rescale_beta(posttest,1,6) ~ scale(pretest) * condition, data = d_sum_intent)
```

By AIC, the beta regression model is very strongly preferred, with AIC = `r round(AIC(fit_beta_intent),1)` versus `r round(AIC(fit_lm_intent_scaled),1)`.

## Ordinal HLM

Again, this is likely the most appropriate analysis for these data.

```{r}
# fit_brm_cum_posttest_intent <- brm(
#   posttest ~ pretest + condition + (1 | workerId) + (1 | item),
#   data = d %>% filter(Scale=="vaxIntent") %>% spread(phase, rating),
#   family = cumulative(), # student(), #cumulative(), #bernoulli(), etc
#   control = list(adapt_delta = .85),
#   cores = parallel::detectCores(),
#   iter = 2000
# )
```

```{r}
# summary(fit_brm_cum_posttest_intent)
```

# Summary

This study successfully replicated the original findings of the _PNAS_ paper according to both its "direct replication" criterion and the "best model" criterion. The "disease risk" manipulation significantly improved attitudes toward vaccines as measured by the 5-item "vaccine attitudes" scale. The intervention also increased participants' reported intentions to vaccinate their children, as measured by our new 5-item "vaccine intentions" scale.

### Replication notes

Analyses can be replicated using `derekpowell/rstudio-dmp:20180321` Docker image.

### `sessionInfo()`

```{r}
sessionInfo()
```

